Demonstre por indução que

1+∑n−1i=0T(i)=2n

Importante: escolha a condição inicial coerente com a fórmula, o algoritimo analisado e que permite chegar a esse resultado.

Qual é a condição inicial?
Apresente a demonstração passo a passo.
A referência no livro texto é Cap. 15, fórmula 15.3

nota: a ferramenta de edição de fórmulas do e-disciplinas funciona adequadamente se as linhas da fórmula renderizada forem mais curtas que a moldura do editor. Para quebrar linhas na ferramenta de fórmulas use dois backslashes (\\)

Texto de resposta Questão 1
Demonstração por Indução



Demonstrar que:

1+∑n−1i=0T(i)=2n

por indução.



1. Condição inicial



Escolhe-se n=1
 como a condição inicial. Nesse caso:

1+∑0i=0T(i)=1+T(0).

A fórmula sugere que 1+∑n−1i=0T(i)=2n
. Para n=1
, verifica-se:

1+T(0)=21=2.



Conclui-se, portanto, que:

T(0)=1.



2. Hipótese de indução

Assume-se que a fórmula é válida para n=k
, ou seja:

1+∑k−1i=0T(i)=2k.



3. Passo indutivo

Deve-se mostrar que a fórmula também vale para n=k+1
, isto é:

1+∑ki=0T(i)=2k+1.



Reescreve-se o lado esquerdo:

1+∑ki=0T(i)=1+(∑k−1i=0T(i)+T(k)).



Substitui-se a hipótese de indução:

\( 1 + \sum_{i=0}^{k} T(i) = 2^k + T(k). \)



Sabe-se que T(k)=2k
 (baseado na relação recursiva do problema):

2k+T(k)=2k+2k=2⋅2k=2k+1.



Conclui-se, então, que a fórmula é válida para n=k+1
.



Conclusão:

Por indução matemática, demonstra-se que:

1+∑n−1i=0T(i)=2n.

Questão 2
Completo
Vale 3,00 ponto(s).
Marcar questão
Texto da questão
Considere o algoritmo que maximiza o retorno no problema do corte da barra (livro texto seção 15.1). A função CUT-ROD(...) tem a árvore de recursão (árvore de execução), para uma barra de comprimento 4, apresentada na figura 15.3

Como essa árvore de recursão se relaciona com o tempo de execução do algoritmo? Por exemplo, o que os nós da árvore representam em termos de tempo de execução, entre outras características.
Considere implementar memoization , como em MEMOIZED-CUT-ROD(...). Ajuste a árvore de recursão da figura 15.3 de maneira a representar a execução de MEMOIZED-CUT-ROD(...). Explique como chegou a essa resposta.
Com base na árvore de recursão apresentada na resposta ao ítem 2, apresente a complexidade de tempo de MEMOIZED-CUT-ROD(...) e justifique.
notas: caso queira inserir imagens, use a ferramenta de inserção de imagens.

          Tenha cautela ao acrescentar conteúdo HTML, código e tabelas. O editor do e-disciplinas tem algum problema para inserir texto verbatim (tag <pre>).





Texto de resposta Questão 2
Análise do Problema do Corte da Barra



O objetivo é analisar a relação entre a árvore de recursão e o tempo de execução do algoritmo CUT-ROD para uma barra de comprimento 4, conforme a Figura 15.3 do livro. Além disso, necessário ajustar a árvore para representar a execução do algoritmo com memoização (MEMOIZED-CUT-ROD) e determinar a complexidade de tempo associada.



1. Árvore de Recursão para CUT-ROD



A árvore de recursão para uma barra de comprimento 4, sem memoização, apresenta a seguinte estrutura:

arvore de execução

Nesta árvore:

- Cada nó representa uma chamada recursiva para CUT-ROD.

- O tempo de execução corresponde ao número total de nós da árvore, pois cada nó executa cálculos para encontrar o retorno máximo.

- Existe uma redundância significativa, com subproblemas como CUT-ROD(1) e CUT-ROD(0) sendo resolvidos múltiplas vezes.



O número de nós na árvore cresce exponencialmente com o comprimento da barra n
, levando a uma complexidade de tempo O(2n)
.



2. Árvore de Recursão para MEMOIZED-CUT-ROD

Ao usar memoização, os subproblemas são resolvidos apenas uma vez e seus resultados armazenados. A árvore de recursão ajustada é:

arvore de execução

Nesta árvore:

- Cada subproblema é resolvido apenas uma vez, eliminando redundâncias.


- O número total de chamadas é igual ao comprimento da barra n
, uma vez que cada subproblema de tamanho i
 (0≤i≤n
) é resolvido exatamente uma vez.



3. Complexidade de Tempo para MEMOIZED-CUT-ROD

Com memoização, a complexidade de tempo é determinada pelo número de subproblemas resolvidos e pelo custo de cada resolução:

- O número de subproblemas é n
.

- Para cada subproblema, calcula-se o máximo entre n
 opções (uma para cada possível corte), resultando em O(n)
 operações.



Portanto, a complexidade total é:

T(n)=O(n2).



Conclusão

- Sem memoização, a complexidade de tempo é O(2n)
 devido à redundância na resolução de subproblemas.

- Com memoização, a complexidade reduz para O(n2)
, pois cada subproblema é resolvido apenas uma vez e o custo de cada resolução é linear em relação ao tamanho da barra.

Questão 3
Completo
Vale 2,50 ponto(s).
Marcar questão
Texto da questão
Qual a complexidade de tempo do RADIX-SORT (livro-texto p. 198) quando o algoritmo de ordenação estável usado é MERGE-SORT (livro-texto p. 34). Justifique.

Texto de resposta Questão 3
A complexidade de tempo do RADIX-SORT depende do número de dígitos (d)
 utilizados para representar os elementos do array e da complexidade do algoritmo de ordenação estável subjacente. Quando o algoritmo de ordenação estável é o MERGE-SORT, a análise da complexidade de tempo é a seguinte:



Análise da Complexidade de Tempo do RADIX-SORT com MERGE-SORT

Esta análise segue as definições e descrições apresentadas no livro. O objetivo é determinar a complexidade de tempo do Radix-Sort quando o algoritmo estável utilizado para ordenação é o Merge-Sort.



O Radix-Sort ordena n
 elementos com base em d
 dígitos, do menos significativo para o mais significativo, assumindo que os elementos podem ser comparados dígito a dígito. Ele utiliza um algoritmo de ordenação estável em cada iteração para garantir a preservação da ordem de elementos com dígitos iguais.



Etapas do Radix-Sort:

1. Para cada um dos d
 dígitos dos elementos, realiza-se uma ordenação estável dos n
 elementos baseada no dígito atual.

2. No caso em análise, o algoritmo de ordenação estável utilizado é o Merge-Sort, cuja complexidade é O(nlogn)
.



Complexidade de Tempo do Merge-Sort

O Merge-Sort ordena n
 elementos dividindo-os recursivamente em metades e combinando-os em logn
 níveis. Em cada nível da recursão, a fusão dos elementos ocorre em O(n)
, resultando em uma complexidade total de:

T(n)=O(nlogn).



Complexidade de Tempo Total do Radix-Sort

Como o Radix-Sort realiza d
 iterações, cada uma com complexidade O(nlogn)
, o tempo total é:

\( T(n) = d \cdot O(n \log n). \)



Caso d
 seja constante:

Quando o número de dígitos d
 não varia com o número de elementos n
, o termo d
 é uma constante, e a complexidade de tempo total é:

T(n)=O(nlogn).



Caso d
 cresça com n
:

Se o número de dígitos d
 cresce com n
, por exemplo, quando os números possuem d=O(logn)
 dígitos, a complexidade total se torna:

T(n)=O(d⋅nlogn).



Visualização: Árvore de Execução do Merge-Sort

Para ilustrar o trabalho realizado em uma única iteração do Radix-Sort, apresenta-se a seguir a árvore de execução do Merge-Sort para n=8
:

arvore de execução

Nesta árvore:

- Cada nó representa uma chamada ao Merge-Sort.

- O número de níveis é logn=2
, e o trabalho total em cada nível é O(n)
.

- O custo total da ordenação de n
 elementos é O(nlogn)
.



Visualização: Estrutura do Radix-Sort

A execução completa do Radix-Sort com d
 (exemplo com d = 3) iterações pode ser representada como:

arvore de execução

Cada subárvore corresponde a uma execução do Merge-Sort em uma das d
 iterações.



Conclusão:

Com base na descrição e análise apresentadas:

- O custo de cada iteração do Radix-Sort, usando o Merge-Sort, é O(nlogn)
.

- O número total de iterações é d
, o número de dígitos.



Assim:

1. Se d
 for constante, a complexidade total é O(nlogn)
.

2. Se d
 crescer com n
, por exemplo, d=O(logn)
, a complexidade total é O(d⋅nlogn)
.

Questão 4
Completo
Vale 2,50 ponto(s).
Marcar questão
Texto da questão
Apresenta-se no livro que a complexidade de tempo de pior caso da busca binária é Θ(log(n))
 (ex. 2.3-5). Aplique a técnica de árvores de recursão (recursion-trees), use a estrutura da árvore para demonstrar que a afirmação apresentada no livro é correta.



Texto de resposta Questão 4
Análise da Complexidade de Tempo da Busca Binária no Pior Caso Utilizando Árvores de Recursão

Apresenta-se que a complexidade de tempo de pior caso da busca binária é Θ(log(n))
 . Para demonstrar isso, analisaremos o problema usando a definição formal de Θ(g(n))
 e a técnica de árvores de recursão.



1. Definição Formal de Θ(g(n))

A partir da definição formal de Θ(g(n))
, tem-se:

Θ(g(n))={f(n):∃c1,c2>0,n0>0|0≤c1g(n)≤f(n)≤c2g(n),∀n≥n0}


Neste caso:

- f(n)
 representa o tempo de execução no pior caso da busca binária;

- log(n)
 é a função de referência.



2. Formulação da Recorrência

A busca binária divide o tamanho do problema n
 pela metade em cada etapa, até que reste um único elemento. O tempo de execução f(n)
 no pior caso pode ser descrito pela seguinte recorrência:

f(n)=f(n2)+O(1)


onde: O(1)
 representa o trabalho constante realizado em cada nível da recursão

(comparação do elemento central e decisão de qual metade explorar).



3. Estrutura da Árvore de Recursão

A técnica de árvores de recursão modela a divisão do problema:

    Raiz: O problema inicial de tamanho n
 está na raiz.
    Filhos: Cada nó na árvore representa uma chamada recursiva, onde o tamanho do problema é reduzido pela metade: n/2,n/4,n/8,…
.
    Altura: A altura da árvore é log2(n)
 , pois cada divisão reduz o tamanho n
 pela metade até atingir 1.


3.1 Representação como Árvore de Recursão

A árvore de recursão da busca binária apresenta a redução sucessiva do tamanho do problema até que o caso base seja alcançado (n=1
). A cada nível da árvore, o custo constante c
 é somado para cada nó. A árvore é representada a seguir:

arvore de execução

Legenda: Cada nó representa uma chamada recursiva com o custo associado ao nível. O problema é reduzido pela metade até alcançar o caso base T(1)
.



3.2 Análise do Tempo Total

Em cada nível da árvore:

- O custo em cada nó é constante (c
).

- O número de nós em cada nível é 1,1,1,…
, pois apenas uma subárvore é explorada na busca binária.



O número total de níveis na árvore é proporcional ao número de vezes que o tamanho do problema n
 pode ser dividido por 2 até chegar a 1. Isso é dado por:

\( \text{Número de níveis} = \log_2 n. \)



O custo total T(n)
 é, então, a soma dos custos em todos os níveis:

\( T(n) = c \cdot \log_2 n + \text{termos de ordem constante}. \)

Logo:

O trabalho total T(n)
 é a soma do trabalho em todos os níveis da árvore:

T(n)=O(1)+O(1)+⋯+O(1)(para h=log2(n) níveis).

T(n)=O(log(n)).




4. Aplicação da Definição de Θ(g(n))



Para verificar que f(n)∈Θ(log(n))
, é necessário mostrar que:

c1log(n)≤f(n)≤c2log(n),∀n≥n0


onde c1
 e c2
 são constantes positivas.



4.1. Limite Inferior Ω(log(n))

O trabalho em cada nível é constante O(1)
, e há exatamente ⌊log2(n)⌋+1
 níveis na árvore. Assim, o tempo de execução total f(n)
 é no mínimo proporcional a log(n)
. Existe uma constante c1>0
 tal que:

f(n)≥c1log(n),∀n≥n0.



4.2. Limite Superior O(log(n))

O trabalho por nível é constante O(1)
, e o número total de níveis não excede log2(n)+1
. Logo, o tempo de execução total f(n)
 é no máximo proporcional a log(n)
. Existe uma constante c2>0
 tal que:

f(n)≤c2log(n),∀n≥n0.



4.3. Conclusão

Como f(n)
 é limitado inferiormente por Ω(log(n))
 e superiormente por O(log(n))
 , segue que f(n)∈Θ(log(n))
.